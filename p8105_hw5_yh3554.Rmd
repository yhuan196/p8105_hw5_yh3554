---
title: "p8105_hw5_yh3554"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(viridis)
library(dbplyr)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


## Problem 1

First create a dataframe `full_df`that includes all data files from the directory `data/`and complete path to each file. Then use `map` over paths and read data using the `read_csv` function. 

```{r, message = FALSE, warning = FALSE}
full_df = 
  tibble(
    files = list.files("data/"),
    path = str_c("data/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest(cols = c(data))
```

To tidy data dataframe need to use string manipulations on the file, converting from wide to long, and selecting relevant variables. 

```{r}
tidy_df = 
  full_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome)
```

Creates a plot showing individual data, faceted by group. 

```{r}
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group)
```

Based on the spaghetti plots, the outcome of experiment group increase over time, but the control group not change much over time. The plots suggest high within-subject correlation -- subjects who start above average end up above average, and those that start below average end up below average.


## Problem 2

#### Read the data

```{r}
homicide_df = read_csv("data_homicide/homicide-data.csv", show_col_types = FALSE)
```

#### Table of proportion of missing data

```{r}
homicide_df %>% 
  summarise_at(vars(lat:disposition), .funs = function(x) mean(is.na(x))) %>%
  knitr::kable()
```

#### Describle the raw data

The `homicide_df` is data contains homicides in 50 large U.S. It has `r nrow(homicide_df)` variables and `r ncol(homicide_df)` cases. The key variables are unique id, victim demographic information (first name, last name, age, sex), the location (city, state, latitude, longitude), and disposition. It has `r sum(is.na (homicide_df$lat))` missing latitude information and `r sum(is.na (homicide_df$lon))` missing longitude information.

#### Generate new dataframe

Create `city_state` variable by combining city and state variales. Then summarize within citries to obtain the total number of homicides and number of unsolved homicides (disposition is “Closed without arrest” or “Open/No arrest”).

```{r}
homicide_tidy <- homicide_df %>% 
  mutate(
    city_state = str_c(city, state, sep = ", ")) %>%
  group_by(city_state) %>%
  summarize(
    homi_tot = n(),
    homi_unsolved = sum(disposition == "Closed without arrest") 
    + sum(disposition == "Open/No arrest" )
  ) %>%
  arrange(desc(homi_tot))

head(homicide_tidy)
```

#### Proportion of homicides that are unsolved for city of Baltimore

Calculate proportion of homicides that are unsolved for city of Baltimore using `prop.test` and save output as R object. Apply `broom::tidy` to pull the estimated proportion and confidence interval.

```{r}
prop_test_output <- prop.test(
  homicide_tidy %>%  filter(city_state == "Baltimore, MD") %>% pull(homi_unsolved),
  homicide_tidy %>%  filter(city_state == "Baltimore, MD") %>% pull(homi_tot))
  
save(prop_test_output, file = "prop_test_output.RData")

prop_test_output %>%
  broom::tidy() %>%
  select(estimate, conf.low, conf.high)
```

#### Proportion of homicides that are unsolved for each city

Run `prop.test` to calculate proportion of homicides that are unsolved for each city, first generate a function that 
```{r, warning = FALSE}
prop_test_all_cities <- 
  purrr::map2_df(.x = homicide_tidy$homi_unsolved,
            .y = homicide_tidy$homi_tot,
            ~broom::tidy(prop.test(.x, .y))) %>%
  select(estimate, conf.low, conf.high) %>%
  mutate(city_state = homicide_tidy$city_state) %>%
  relocate(city_state) %>%
  arrange(desc(estimate))

head(prop_test_all_cities)
```

#### Plot of estimated CI for each city

```{r}
prop_test_all_cities %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(title = "Estimate Proportion of unsloved homicides by city", 
       x = "City",
       y = "Estimate") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1), 
        legend.position = "none")
```


## Problem 3

This problem will conduct a simulation to explore power of one sample t test.\
First set up the model and t test\
X ~ N($\mu$, $\sigma$)\
n = 30, $\sigma$ = 5\
$H_0$ : $\mu$ = 0     where $\alpha$ = 0.05\

```{r}
set.seed(1)
sim_fn <- function(n = 30, mu = 0, sigma = 5){
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma))
  
  result = sim_data %>% t.test(mu = 0, alpha = 0.05) %>%
    broom::tidy() %>%
    select(estimate, p.value)
  
  result
}

sim_fn()
```

Then generate a 5000 datasets for the model, repeat the test, and save $\hat{\mu}$ and p-value.

```{r}
sim_mu0 <- expand_grid(mu = 0, iter = 1:5000) %>% 
  mutate(
    est_df = map(.x = mu, ~sim_fn(mu=.x))) %>% 
  unnest(est_df)

head(sim_mu0)
```

Repeat the same process for $\mu$ = {1,2,3,4,5,6}\

```{r}
sim_mus <- expand_grid(mu = 1:6, iter = 1:5000)  %>%
mutate(
    est_df = map(.x = mu, ~sim_fn(mu=.x))) %>% 
  unnest(est_df)

head(sim_mus)
```

Combine the result of $\mu$ = 0 and $\mu$ = {1,2,3,4,5,6}

```{r}
sim_result <- rbind(sim_mu0, sim_mus)
```

#### Plot of proportion of times the null was rejected vs true value of $\mu$

```{r}
sim_result %>%
  group_by(mu) %>%
  summarize(power = sum(p.value < 0.05)/n()) %>%
  ggplot(aes(x = mu, y = power)) + 
  geom_point() + 
  geom_line() +
  labs(title = "Power of t test for true value of mean", 
       x = "True Mean", 
       y = "Power")
```

Based on the plot, power increases as the effect size increase. The greater true mean value has higher proportion of rejecting the corresponding null hypothesis. There is rapid increasing pattern between true mean 0 and true mean 3, it turns to be more and more stable after true mean 4.

#### Plot of average estimate of $\hat{\mu}$ vs true $\mu$

```{r}
sim_result %>% 
  group_by(mu) %>%
  summarize(avg_mu_hat = mean(estimate)) %>%
  ggplot(aes(x = mu, y = avg_mu_hat)) + geom_point(size = 2) + geom_line() +
  labs(title = "Average of all estimates vs. true mean",
       x = "True mean", 
       y = "Average estimates mean")
```

#### Plot of average estimate of $\hat{\mu}$ in samples where null was rejected

```{r}
sim_result %>% 
  filter(p.value < 0.05) %>%
  group_by(mu) %>%
  summarize(avg_mu_hat = mean(estimate)) %>%
  ggplot(aes(x = mu, y = avg_mu_hat)) + geom_point(size = 2) + geom_line() +
  labs(title = "Average of rejectet estimates vs. true mean",
       x = "True mean", 
       y = "Average estimate mean")
```

#### Combine two plots
```{r}
rej_est <- sim_result %>% 
  filter(p.value < 0.05) %>% group_by(mu) %>% 
  summarize(avg_est = mean(estimate)) %>% 
  ungroup()

full_est <- sim_result %>% 
  group_by(mu) %>% 
  summarize(avg_est = mean(estimate)) %>% 
  ungroup()
  
ggplot(full_est,aes(x = mu, y = avg_est)) +
  geom_line(aes(colour = "blue")) +
  geom_line(data = rej_est, aes(color = "red")) +
  scale_color_manual(name = " ", 
                     values = c("blue" = "blue", "red" = "red"),
                     labels = c('All Estimates','Rejected Estimates')) +
  geom_point(data = rej_est, color = "red") +
  labs(title = "All vs Rejected Estimates", 
       x = "True Mean",
       y = "Average estimate mean")
```

Based on the last plot, the sample average of $\hat{\mu}$ across tests for which the null is rejected is not approximately equal to the true value of $\mu$. For true mean 1 to 4, significant difference between average estimated mean for rejected null values and true mean. The simulated values can be very close to true mean or bigger to true mean which would result a bigger estimated mean cause the t test more likely to fail to reject the null.
For true mean of 0 the average estimated mean for rejected null values approximate the true mean because the simulated value could be either positive or negative number which make the estimate mean yields to 0.
Power gets stronger as the effect size increase. For true mean after 4, the average estimated mean for rejected null values approximate the true mean because the simulated values are close to true mean.
